{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdf0b6df-c230-47b6-a176-e50efaae4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.sparse import diags\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0a3f815-553e-4a41-9ceb-8efde87d3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_propagation(G, labels, max_iter=1000, tol=1e-6): \n",
    "    node_to_idx = {node: idx for idx, node in enumerate(G.nodes())}\n",
    "    idx_to_node = {idx: node for node, idx in node_to_idx.items()}\n",
    "    \n",
    "    A = nx.adjacency_matrix(G)\n",
    "    row_sum = np.array(A.sum(axis=1)).flatten()\n",
    "    row_sum[row_sum == 0] = 1  # Prevent division by zero for isolated nodes\n",
    "    \n",
    "    # Normalize rows of the sparse matrix\n",
    "    Dinv = diags(1.0 / row_sum)\n",
    "    P = Dinv @ A  # Transition probability matrix\n",
    "    \n",
    "    n_nodes = len(G.nodes)\n",
    "    unique_labels = sorted(set(labels.values()))\n",
    "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    Y = np.zeros((n_nodes, len(unique_labels)))\n",
    "    \n",
    "    for node, label in labels.items():\n",
    "        if label is not None:\n",
    "            Y[node_to_idx[node], label_to_index[label]] = 1\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        Y_prev = Y.copy()\n",
    "        Y = P.dot(Y)\n",
    "        for node in labels:\n",
    "            if labels[node] is not None:\n",
    "                Y[node_to_idx[node], :] = Y_prev[node_to_idx[node], :]\n",
    "        if np.linalg.norm(Y - Y_prev) < tol:\n",
    "            break\n",
    "    \n",
    "    index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
    "    predicted_labels = {}\n",
    "    for idx in range(n_nodes):\n",
    "        node = idx_to_node[idx]\n",
    "        if Y[idx].sum() > 0:  # Check if row contains any non-zero values\n",
    "            predicted_labels[node] = index_to_label[np.argmax(Y[idx, :])]\n",
    "    \n",
    "    return predicted_labels\n",
    "\n",
    "def randomly_remove_attributes(node_attrs, remove_fraction):\n",
    "    known_labels = {node: attr for node, attr in node_attrs.items() if attr is not None}\n",
    "    if not known_labels:  # Handle case with no valid labels\n",
    "        return node_attrs.copy(), {}\n",
    "    \n",
    "    total_to_remove = int(len(known_labels) * remove_fraction)\n",
    "    removed_nodes = random.sample(list(known_labels.keys()), total_to_remove)\n",
    "    incomplete_attrs = node_attrs.copy()\n",
    "    for node in removed_nodes:\n",
    "        incomplete_attrs[node] = None\n",
    "    return incomplete_attrs, {node: attr for node, attr in node_attrs.items() if node not in removed_nodes and attr is not None}\n",
    "\n",
    "def evaluate_label_propagation(G, node_attrs, remove_fractions):\n",
    "    results = {}\n",
    "    for fraction in remove_fractions:\n",
    "        incomplete_attrs, labeled_attrs = randomly_remove_attributes(node_attrs, fraction)\n",
    "        if not labeled_attrs: \n",
    "            continue\n",
    "            \n",
    "        predicted_labels = label_propagation(G, labeled_attrs)\n",
    "        \n",
    "        missing_nodes = [node for node in incomplete_attrs if incomplete_attrs[node] is None]\n",
    "        true_labels = [node_attrs[node] for node in missing_nodes if node in node_attrs and node_attrs[node] is not None]\n",
    "        recovered_labels = [predicted_labels.get(node) for node in missing_nodes if node in predicted_labels]\n",
    "        \n",
    "        if true_labels and recovered_labels: \n",
    "            accuracy = sum(1 for y, y_pred in zip(true_labels, recovered_labels) if y == y_pred) / len(true_labels)\n",
    "            mae = sum(abs(float(y) - float(y_pred)) for y, y_pred in zip(true_labels, recovered_labels)) / len(true_labels)\n",
    "            results[f\"{fraction * 100}% Removed\"] = {\"accuracy\": accuracy, \"mae\": mae}\n",
    "            \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88aeeef0-c4d8-481c-8f52-6b66554da4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for attribute: dorm\n",
      "10.0% Removed: Accuracy = 0.7170, Mean Square Error: = 70.22939380723942\n",
      "20.0% Removed: Accuracy = 0.6939, Mean Square Error: = 75.3675604970569\n",
      "30.0% Removed: Accuracy = 0.7051, Mean Square Error: = 72.4381630576951\n",
      "\n",
      "Results for attribute: major_index\n",
      "10.0% Removed: Accuracy = 0.2835, Mean Square Error: = 123.90274749236808\n",
      "20.0% Removed: Accuracy = 0.1838, Mean Square Error: = 128.42598648354044\n",
      "30.0% Removed: Accuracy = 0.1110, Mean Square Error: = 140.76849295160588\n",
      "\n",
      "Results for attribute: gender\n",
      "10.0% Removed: Accuracy = 0.5552, Mean Square Error: = 0.4749236807675534\n",
      "20.0% Removed: Accuracy = 0.5609, Mean Square Error: = 0.47351209941138\n",
      "30.0% Removed: Accuracy = 0.5630, Mean Square Error: = 0.4705711379160006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../Data/fb100\"\n",
    "caltech = nx.read_gml(f\"{data_path}/Berkeley13.gml\")\n",
    "attributes_to_evaluate = ['dorm', 'major_index', 'gender']\n",
    "remove_fractions = [0.1, 0.2, 0.3]\n",
    "\n",
    "for attr_name in attributes_to_evaluate:\n",
    "    attr_data = {node: caltech.nodes[node][attr_name] \n",
    "                 for node in caltech.nodes \n",
    "                 if caltech.nodes[node].get(attr_name) is not None}\n",
    "    \n",
    "    results = evaluate_label_propagation(caltech, attr_data, remove_fractions)\n",
    "    \n",
    "    print(f\"Results for attribute: {attr_name}\")\n",
    "    for fraction, result in results.items():\n",
    "        print(f\"{fraction}: Accuracy = {result['accuracy']:.4f}, Mean Square Error: = {result['mae']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e484ff-0519-4ad0-88b2-0172f7e24b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
